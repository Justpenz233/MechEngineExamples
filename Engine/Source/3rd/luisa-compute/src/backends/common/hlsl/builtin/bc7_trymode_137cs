[numthreads( THREAD_GROUP_SIZE, 1, 1 )]
void main( uint GI : SV_GroupIndex, uint3 groupID : SV_GroupID ) // mode 1 3 7 all have 2 subsets per block
{
 const uint MAX_USED_THREAD = 64;
 uint BLOCK_IN_GROUP = THREAD_GROUP_SIZE / MAX_USED_THREAD;
 uint blockInGroup = GI / MAX_USED_THREAD;
 uint blockID = g_start_block_id + groupID.x * BLOCK_IN_GROUP + blockInGroup;
 uint threadBase = blockInGroup * MAX_USED_THREAD;
 uint threadInBlock = GI - threadBase;

 uint block_y = blockID / g_num_block_x;
 uint block_x = blockID - block_y * g_num_block_x;
 uint base_x = block_x * BLOCK_SIZE_X;
 uint base_y = block_y * BLOCK_SIZE_Y;
 
 if (threadInBlock < 16)
 {
 shared_temp[GI].pixel = clamp(uint4(g_Input.Load( uint3( base_x + threadInBlock % 4, base_y + threadInBlock / 4, 0 ) ) * 255), 0, 255);
 }
 GroupMemoryBarrierWithGroupSync();

 shared_temp[GI].error = 0xFFFFFFFF;

 uint4 pixel_r;
 uint2x4 endPoint[2]; // endPoint[0..1 for subset id][0..1 for low and high in the subset]
 uint2x4 endPointBackup[2];
 uint color_index;
 if (threadInBlock < 64)
 {
 uint partition = threadInBlock;

 endPoint[0][0] = MAX_UINT;
 endPoint[0][1] = MIN_UINT;
 endPoint[1][0] = MAX_UINT;
 endPoint[1][1] = MIN_UINT;
 uint bits = candidateSectionBit[partition];
 for ( uint i = 0; i < 16; i ++ )
 {
 uint4 pixel = shared_temp[threadBase + i].pixel;
 if ( (( bits >> i ) & 0x01) == 1 )
 {
 endPoint[1][0] = min( endPoint[1][0], pixel );
 endPoint[1][1] = max( endPoint[1][1], pixel );
 }
 else
 {
 endPoint[0][0] = min( endPoint[0][0], pixel );
 endPoint[0][1] = max( endPoint[0][1], pixel );
 }
 }

 endPointBackup[0] = endPoint[0];
 endPointBackup[1] = endPoint[1];

 uint max_p;
 if (1 == g_mode_id)
 {
 // in mode 1, there is only one p bit per subset
 max_p = 2;
 }
 else
 {
 // in mode 3 7, there are two p bits per subset, one for each end point
 max_p = 4;
 }

 uint final_p[2] = { 0, 0 };
 uint error[2] = { MAX_UINT, MAX_UINT };
 for ( uint p = 0; p < max_p; p ++ )
 {
 endPoint[0] = endPointBackup[0];
 endPoint[1] = endPointBackup[1];

 for (uint i = 0; i < 2; i ++ ) // loop through 2 subsets
 {
 if (g_mode_id == 1)
 {
 compress_endpoints1( endPoint[i], p );
 }
 else if (g_mode_id == 3)
 {
 compress_endpoints3( endPoint[i], uint2(p, p >> 1) & 1 );
 }
 else if (g_mode_id == 7)
 {
 compress_endpoints7( endPoint[i], uint2(p, p >> 1) & 1 );
 }
 }

 int4 span[2];
 span[0] = endPoint[0][1] - endPoint[0][0];
 span[1] = endPoint[1][1] - endPoint[1][0];

 if (g_mode_id != 7)
 {
 span[0].w = span[1].w = 0;
 }

 int span_norm_sqr[2];
 span_norm_sqr[0] = dot( span[0], span[0] );
 span_norm_sqr[1] = dot( span[1], span[1] );

 // TODO: again, this shouldn't be necessary here in error calculation
 int dotProduct = dot( span[0], shared_temp[threadBase + 0].pixel - endPoint[0][0] );
 if ( span_norm_sqr[0] > 0 && dotProduct > 0 && uint( dotProduct * 63.49999 ) > uint( 32 * span_norm_sqr[0] ) )
 {
 span[0] = -span[0];
 swap(endPoint[0][0], endPoint[0][1]);
 }
 dotProduct = dot( span[1], shared_temp[threadBase + candidateFixUpIndex1D[partition].x].pixel - endPoint[1][0] );
 if ( span_norm_sqr[1] > 0 && dotProduct > 0 && uint( dotProduct * 63.49999 ) > uint( 32 * span_norm_sqr[1] ) )
 {
 span[1] = -span[1];
 swap(endPoint[1][0], endPoint[1][1]);
 }

 uint step_selector;
 if (g_mode_id != 1)
 {
 step_selector = 2; // mode 3 7 have 2 bit index
 }
 else
 {
 step_selector = 1; // mode 1 has 3 bit index
 }

 uint p_error[2] = { 0, 0 };
 for (uint i = 0; i < 16; i ++ )
 {
 uint subset_index = (bits >> i) & 0x01;

 if (subset_index == 1)
 {
 dotProduct = dot( span[1], shared_temp[threadBase + i].pixel - endPoint[1][0] );
 color_index = (span_norm_sqr[1] <= 0 || dotProduct <= 0) ? 0
 : ((dotProduct < span_norm_sqr[1]) ? aStep[step_selector][uint(dotProduct * 63.49999 / span_norm_sqr[1])] : aStep[step_selector][63]);
 }
 else
 {
 dotProduct = dot( span[0], shared_temp[threadBase + i].pixel - endPoint[0][0] );
 color_index = (span_norm_sqr[0] <= 0 || dotProduct <= 0) ? 0
 : ((dotProduct < span_norm_sqr[0]) ? aStep[step_selector][uint(dotProduct * 63.49999 / span_norm_sqr[0])] : aStep[step_selector][63]);
 }

 pixel_r = ((64 - aWeight[step_selector][color_index]) * endPoint[subset_index][0]
 + aWeight[step_selector][color_index] * endPoint[subset_index][1] + 32) >> 6;
 if (g_mode_id != 7)
 {
 pixel_r.a = 255;
 }

 uint4 pixel = shared_temp[threadBase + i].pixel;
 Ensure_A_Is_Larger( pixel_r, pixel );
 pixel_r -= pixel;
 uint pixel_error = ComputeError(pixel_r, pixel_r);
 if ( subset_index == 1 )
 p_error[1] += pixel_error;
 else
 p_error[0] += pixel_error;
 }

 for (uint i = 0; i < 2; i++ )
 {
 if (p_error[i] < error[i])
 {
 error[i] = p_error[i];
 final_p[i] = p;
 }
 }
 }

 shared_temp[GI].error = error[0] + error[1];
 shared_temp[GI].mode = g_mode_id;
 shared_temp[GI].partition = partition;

 // mode 1 3 7 don't have rotation, we use rotation for p bits
 if ( g_mode_id == 1 )
 shared_temp[GI].rotation = (final_p[1] << 1) | final_p[0];
 else
 shared_temp[GI].rotation = (final_p[1] << 2) | final_p[0];
 }
 GroupMemoryBarrierWithGroupSync();

 if (threadInBlock < 32)
 {
 if ( shared_temp[GI].error > shared_temp[GI + 32].error )
 {
 shared_temp[GI].error = shared_temp[GI + 32].error;
 shared_temp[GI].mode = shared_temp[GI + 32].mode;
 shared_temp[GI].partition = shared_temp[GI + 32].partition;
 shared_temp[GI].rotation = shared_temp[GI + 32].rotation;
 }
 }
 #ifdef REF_DEVICE
 GroupMemoryBarrierWithGroupSync();
 #endif
 if (threadInBlock < 16)
 {
 if ( shared_temp[GI].error > shared_temp[GI + 16].error )
 {
 shared_temp[GI].error = shared_temp[GI + 16].error;
 shared_temp[GI].mode = shared_temp[GI + 16].mode;
 shared_temp[GI].partition = shared_temp[GI + 16].partition;
 shared_temp[GI].rotation = shared_temp[GI + 16].rotation;
 }
 }
 #ifdef REF_DEVICE
 GroupMemoryBarrierWithGroupSync();
 #endif
 if (threadInBlock < 8)
 {
 if ( shared_temp[GI].error > shared_temp[GI + 8].error )
 {
 shared_temp[GI].error = shared_temp[GI + 8].error;
 shared_temp[GI].mode = shared_temp[GI + 8].mode;
 shared_temp[GI].partition = shared_temp[GI + 8].partition;
 shared_temp[GI].rotation = shared_temp[GI + 8].rotation;
 }
 }
 #ifdef REF_DEVICE
 GroupMemoryBarrierWithGroupSync();
 #endif
 if (threadInBlock < 4)
 {
 if ( shared_temp[GI].error > shared_temp[GI + 4].error )
 {
 shared_temp[GI].error = shared_temp[GI + 4].error;
 shared_temp[GI].mode = shared_temp[GI + 4].mode;
 shared_temp[GI].partition = shared_temp[GI + 4].partition;
 shared_temp[GI].rotation = shared_temp[GI + 4].rotation;
 }
 }
 #ifdef REF_DEVICE
 GroupMemoryBarrierWithGroupSync();
 #endif
 if (threadInBlock < 2)
 {
 if ( shared_temp[GI].error > shared_temp[GI + 2].error )
 {
 shared_temp[GI].error = shared_temp[GI + 2].error;
 shared_temp[GI].mode = shared_temp[GI + 2].mode;
 shared_temp[GI].partition = shared_temp[GI + 2].partition;
 shared_temp[GI].rotation = shared_temp[GI + 2].rotation;
 }
 }
 #ifdef REF_DEVICE
 GroupMemoryBarrierWithGroupSync();
 #endif
 if (threadInBlock < 1)
 {
 if ( shared_temp[GI].error > shared_temp[GI + 1].error )
 {
 shared_temp[GI].error = shared_temp[GI + 1].error;
 shared_temp[GI].mode = shared_temp[GI + 1].mode;
 shared_temp[GI].partition = shared_temp[GI + 1].partition;
 shared_temp[GI].rotation = shared_temp[GI + 1].rotation;
 }

 if (g_InBuff[blockID].x > shared_temp[GI].error)
 {
 g_OutBuff[blockID] = uint4(shared_temp[GI].error, shared_temp[GI].mode, shared_temp[GI].partition, shared_temp[GI].rotation); // mode 1 3 7 don't have rotation, we use rotation for p bits
 }
 else
 {
 g_OutBuff[blockID] = g_InBuff[blockID];
 }
 }
}
